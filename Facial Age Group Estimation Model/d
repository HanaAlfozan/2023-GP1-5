{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b7b6dd-1cf0-4c2c-b124-a062ca3077d7",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Augmentation for Datasets (2 dataset is used)\n",
    "\n",
    "\n",
    "The first data set: https://www.kaggle.com/datasets/mariafrenti/age-prediction\n",
    "\n",
    "The second data set: https://www.kaggle.com/datasets/frabbisw/facial-age/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08614719",
   "metadata": {},
   "source": [
    "Data AugmentationSince our dataset is imbalanced we do a technique named stratified splitting that data splitting method that preserves the class distribution in training and testing sets, ensuring each class is represented proportionally for more accurate model assessment.\n",
    "\n",
    "\n",
    "\n",
    "since the images in class 9+ and 4+ are less i do the following split and then make augmentation on the training set to make them more balanced:\n",
    "\n",
    "For 4+, 9+  : \n",
    "\n",
    "80% of the data for training\n",
    "\n",
    "10% of the data for validation\n",
    "\n",
    "10% of the data for testing\n",
    "\n",
    "For 0-3, 12+ ,17+:\n",
    "\n",
    " 70% of the data for training\n",
    "\n",
    " 15% of the data for validation\n",
    "\n",
    " 15% of the data for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164359da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Define your dataset directory and class labels\n",
    "dataset_dir = 'FDB'\n",
    "class_labels = ['0-3', '12+', '17+']  # class labels\n",
    "class_labels_2 = ['4+', '9+']\n",
    "\n",
    "# Define data split ratios for class_labels\n",
    "train_split = 0.7  # 70% of the data for training\n",
    "val_split = 0.15  # 15% of the data for validation\n",
    "test_split = 0.15  # 15% of the data for testing\n",
    "\n",
    "# Define data split ratios for class_labels_2\n",
    "train_split2 = 0.8  # 80% of the data for training\n",
    "val_split2 = 0.1  # 10% of the data for validation\n",
    "test_split2 = 0.1  # 10% of the data for testing\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# Create train, validation, and test directories\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'validation')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Subdirectory Creation\n",
    "for dir in [train_dir, val_dir, test_dir]:\n",
    "    for label in class_labels + class_labels_2:\n",
    "        os.makedirs(os.path.join(dir, label), exist_ok=True)\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# Split data into train, validation, and test directories for class_labels\n",
    "for label in class_labels:\n",
    "    label_dir = os.path.join(dataset_dir, label)\n",
    "    images = os.listdir(label_dir)\n",
    "    num_images = len(images)\n",
    "\n",
    "    train_split_idx = int(num_images * train_split)\n",
    "    val_split_idx = int(num_images * (train_split + val_split))\n",
    "\n",
    "    train_images = images[:train_split_idx]\n",
    "    val_images = images[train_split_idx:val_split_idx]\n",
    "    test_images = images[val_split_idx:]\n",
    "\n",
    "    for image in train_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(train_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "    for image in val_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(val_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "    for image in test_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(test_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# Split data into train, validation, and test directories for class_labels_2\n",
    "for label in class_labels_2:\n",
    "    label_dir = os.path.join(dataset_dir, label)\n",
    "    images = os.listdir(label_dir)\n",
    "    num_images = len(images)\n",
    "\n",
    "    train_split_idx = int(num_images * train_split2)\n",
    "    val_split_idx = int(num_images * (train_split2 + val_split2))\n",
    "\n",
    "    train_images = images[:train_split_idx]\n",
    "    val_images = images[train_split_idx:val_split_idx]\n",
    "    test_images = images[val_split_idx:]\n",
    "\n",
    "    for image in train_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(train_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "    for image in val_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(val_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "    for image in test_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(test_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "#--------------------------------\n",
    "# Delete old directories (empty)\n",
    "for label in class_labels + class_labels_2 :\n",
    "    label_dir = os.path.join(dataset_dir, label)\n",
    "    os.rmdir(label_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "034dbcbc-c20c-44fb-8314-d159411f71a1",
   "metadata": {},
   "source": [
    "So, after running this code, your dataset will be organized into three main directories, each containing subdirectories for class labels, with images appropriately split into training, validation, and test sets according to the specified ratios. \n",
    "This organization is typically done as a preprocessing step before training a machine learning model on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf298c9",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd9872-fbbf-4b31-97f8-1474cd42cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "\n",
    "#Augmenting 4+ class to make the classes more balanced\n",
    "image_data_path=\"FDB/train/4+\"\n",
    "p1 = Augmentor.Pipeline(image_data_path)\n",
    "\n",
    "# modifing the image's property \n",
    "p1.flip_left_right(probability=0.8)\n",
    "p1.random_brightness(probability=0.9, min_factor=0.4, max_factor=1.1)\n",
    "p1.rotate(probability=0.6, max_left_rotation=14, max_right_rotation=14)\n",
    "p1.sample(379)\n",
    "#--------------------------------\n",
    "#Augmenting 4+ class to make the classes more balanced\n",
    "image_data_path=\"FDB/train/9+\"\n",
    "p1 = Augmentor.Pipeline(image_data_path)\n",
    "\n",
    " # Add augmentation operations with the max_times parameter to control the number of times they can be applied\n",
    "p1.flip_left_right(probability=0.8)\n",
    "p1.random_brightness(probability=0.9, min_factor=0.4, max_factor=1.1)\n",
    "p1.rotate(probability=0.6, max_left_rotation=14, max_right_rotation=14)\n",
    "p1.sample(313)\n",
    "\n",
    "#--------------------------------\n",
    "#Augmenting 4+ class to make the classes more balanced\n",
    "image_data_path=\"FDB/train/4+\"\n",
    "p1 = Augmentor.Pipeline(image_data_path)\n",
    "\n",
    "    # Add augmentation operations with the max_times parameter to control the number of times they can be applied\n",
    "p1.flip_left_right(probability=0.8)\n",
    "p1.random_brightness(probability=0.9, min_factor=0.4, max_factor=1.1)\n",
    "p1.rotate(probability=0.6, max_left_rotation=14, max_right_rotation=14)\n",
    "p1.sample(116)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
