{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b7b6dd-1cf0-4c2c-b124-a062ca3077d7",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Data Splitting for Datasets (5 dataset is used)\n",
    "\n",
    "\n",
    "The first data set: https://www.kaggle.com/datasets/mariafrenti/age-prediction\n",
    "\n",
    "The second data set: https://www.kaggle.com/datasets/frabbisw/facial-age/data\n",
    "\n",
    "The third data set: https://www.kaggle.com/datasets/mostafaebrahiem/egyptian-kids-faces\n",
    "\n",
    "The forth data set: https://www.kaggle.com/datasets/tunguz/1-million-fake-faces?select=1m_faces_00_01_02_03\n",
    "\n",
    "The fifth data set: https://www.kaggle.com/datasets/xhlulu/flickrfaceshq-dataset-nvidia-resized-256px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - cropping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model from OpenCV\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Path to the folder containing the images\n",
    "folder_path = \"0-3\"  # Replace it for each needed class with the actual folder path\n",
    "\n",
    "# Output folder to save the processed images\n",
    "output_folder = \"0-3\"  # Replace it for each needed class\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through the images in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Process image files only\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Load the image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Check if the image is loaded successfully\n",
    "        if img is None:\n",
    "            print(f\"Failed to load or corrupted: {img_path}\")\n",
    "            continue  # Skip to the next image\n",
    "\n",
    "        # Detect faces in the image\n",
    "        faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Iterate through detected faces\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # Expand the region to include more of the face\n",
    "            expand_factor = 0.05  # Adjust this factor to control the zoom level (0.05 , 0.1), based on whether or not the faces are near and clear in the images.\n",
    "            x -= int(w * expand_factor)\n",
    "            y -= int(h * expand_factor)\n",
    "            w += int(2 * w * expand_factor)\n",
    "            h += int(2 * h * expand_factor)\n",
    "\n",
    "            # Ensure the expanded region is within the image boundaries\n",
    "            x = max(x, 0)\n",
    "            y = max(y, 0)\n",
    "            w = min(w, img.shape[1])\n",
    "            h = min(h, img.shape[0])\n",
    "\n",
    "            # Crop the detected face from the image (original color)\n",
    "            face_img = img[y:y+h, x:x+w]\n",
    "\n",
    "            # Modify the output filename to include \"_cropped.jpg\"\n",
    "            base_filename, ext = os.path.splitext(filename)\n",
    "            output_filename = f\"{base_filename}_cropped.jpg\" \n",
    "\n",
    "            # Save the cropped face image with the modified filename\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(output_path, face_img)\n",
    "\n",
    "\n",
    "# It's not moving the undetected faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Resizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def is_image_file(filename):\n",
    "    # Check if the file has a valid image extension\n",
    "    valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\")\n",
    "    return filename.lower().endswith(valid_extensions)\n",
    "\n",
    "def resize_image(input_path, output_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize an image to the target size using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Path to the input image file.\n",
    "        output_path (str): Path to save the resized image.\n",
    "        target_size (tuple): A tuple (width, height) specifying the target size.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is not None:\n",
    "        if not image.size == 0:\n",
    "            resized_image = cv2.resize(image, target_size)\n",
    "            cv2.imwrite(output_path, resized_image)\n",
    "        else:\n",
    "            print(f\"Warning: {input_path} is an empty image.\")\n",
    "    else:\n",
    "        print(f\"Error: Failed to read {input_path}\")\n",
    "\n",
    "# Directory containing dataset of images\n",
    "dataset_dir = \"12+\"   # Replace it for each needed class\n",
    "\n",
    "# Directory to save the resized images\n",
    "output_dir = \"12+\" #Replace it for each needed class\n",
    "\n",
    "# Set the target size (224x224 pixels)\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List all files in the dataset directory\n",
    "file_list = os.listdir(dataset_dir)\n",
    "\n",
    "# Create a list to store resized image filenames\n",
    "resized_image_filenames = []\n",
    "\n",
    "# Loop through each image in the dataset\n",
    "for filename in file_list:\n",
    "    if is_image_file(filename):\n",
    "        # Construct the full path of the image\n",
    "        input_path = os.path.join(dataset_dir, filename)\n",
    "        \n",
    "        # Construct the output path for the resized image\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Resize the image and save it\n",
    "        resize_image(input_path, output_path, target_size)\n",
    "\n",
    "        # Add the resized image filename to the list\n",
    "        resized_image_filenames.append(output_path)\n",
    "\n",
    "print(\"Resizing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08614719",
   "metadata": {},
   "source": [
    "### It is use the deterministic splitting strategy based on the order of the images within each class label directory.\n",
    "\n",
    "\n",
    "so the spliting for the class label is: 0-3,4+, 9+ , 12+ ,17+:\n",
    "\n",
    "80% of the data for training\n",
    "\n",
    "10% of the data for validation\n",
    "\n",
    "10% of the data for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164359da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting complete\n"
     ]
    }
   ],
   "source": [
    "# Define your dataset directory and class labels\n",
    "dataset_dir = 'Faces_images'\n",
    "class_labels = ['0-3','4+', '9+', '12+', '17+']  # class labels\n",
    "\n",
    "# Define data split ratios for class_labels\n",
    "train_split = 0.8 # 80% of the data for training\n",
    "val_split = 0.1  # 10% of the data for validation\n",
    "test_split = 0.1 # 10% of the data for testing\n",
    "\n",
    "\n",
    "\n",
    "# Create train, validation, and test directories\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'validation')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Subdirectory Creation\n",
    "for dir in [train_dir, val_dir, test_dir]:\n",
    "    for label in class_labels:\n",
    "        os.makedirs(os.path.join(dir, label), exist_ok=True)\n",
    "\n",
    "\n",
    "# Split data into train, validation, and test directories for class_labels\n",
    "for label in class_labels:\n",
    "    label_dir = os.path.join(dataset_dir, label)\n",
    "    images = os.listdir(label_dir)\n",
    "    num_images = len(images)\n",
    "\n",
    "    train_split_idx = int(num_images * train_split) # calculate index up to which images will be used for training (80% of the data).\n",
    "    val_split_idx = int(num_images * (train_split + val_split)) # calculate index up to which images will be used for validation (10% of the data in addition to the training set).\n",
    "\n",
    "    train_images = images[:train_split_idx] #images from index 0 to train_split_idx - 1\n",
    "    val_images = images[train_split_idx:val_split_idx] # images from index train_split_idx to val_split_idx - 1.\n",
    "    test_images = images[val_split_idx:] #remaining images after the training and validation sets are defined.\n",
    "\n",
    "    # Move Images to Respective Directories:\n",
    "    for image in train_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(train_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "    for image in val_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(val_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "    for image in test_images:\n",
    "        src = os.path.join(label_dir, image)\n",
    "        dest = os.path.join(test_dir, label, image)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "# Delete old directories (empty)\n",
    "for label in class_labels  :\n",
    "    label_dir = os.path.join(dataset_dir, label)\n",
    "    os.rmdir(label_dir)\n",
    "\n",
    "print(\"Splitting complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, after running this code, the dataset is organized into three main directories, each containing subdirectories for class labels, with images appropriately split into training, validation, and test sets according to the specified ratios.\n",
    "#### This organization is typically done  to ensure each class has more than half of real face images, as well as as a step before training a machine learning model on the dataset.\n",
    "#### This predictability can be useful for reproducibility in research or when you want to ensure that the data split remains constant across different runs of the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
